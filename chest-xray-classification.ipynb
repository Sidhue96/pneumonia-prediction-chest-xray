{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()  \n\nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"Using CUDA\")","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_dir = '../input/chest-xray-pneumonia/chest_xray/chest_xray'\nTEST = 'test'\nTRAIN = 'train'\nVAL = 'val'\n\ndata_transforms = {\n    TRAIN: transforms.Compose([\n        # Data augmentation is a good practice for the train set\n        # Here, we randomly crop the image to 224x224 and\n        # randomly flip it horizontally. \n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]),\n    VAL: transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ]),\n    TEST: transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ])\n}\n\nimage_datasets = {\n    x: datasets.ImageFolder(\n        os.path.join(data_dir, x), \n        transform=data_transforms[x]\n    )\n    for x in [TRAIN, VAL, TEST]\n}\n\ndataloaders = {\n    x: torch.utils.data.DataLoader(\n        image_datasets[x], batch_size=8,\n        shuffle=True, num_workers=4\n    )\n    for x in [TRAIN, VAL, TEST]\n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n\nfor x in [TRAIN, VAL, TEST]:\n    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n    \nprint(\"Classes: \")\nclass_names = image_datasets[TRAIN].classes\nprint(image_datasets[TRAIN].classes)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f912ad37663b562288f9becf3d1102b677e13ddd"},"cell_type":"code","source":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    # plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n\ndef show_databatch(inputs, classes):\n    out = torchvision.utils.make_grid(inputs)\n    imshow(out, title=[class_names[x] for x in classes])\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders[TRAIN]))\nshow_databatch(inputs, classes)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3dcb620ada432b8694cedfb29a34a04bf1892ef6"},"cell_type":"code","source":"def visualize_model(vgg, num_images=6):\n    was_training = vgg.training\n    \n    # Set model for evaluation\n    vgg.train(False)\n    vgg.eval() \n    \n    images_so_far = 0\n\n    for i, data in enumerate(dataloaders[TEST]):\n        inputs, labels = data\n        size = inputs.size()[0]\n        \n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n        else:\n            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n        \n        outputs = vgg(inputs)\n        \n        _, preds = torch.max(outputs.data, 1)\n        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n        \n        print(\"Ground truth:\")\n        show_databatch(inputs.data.cpu(), labels.data.cpu())\n        print(\"Prediction:\")\n        show_databatch(inputs.data.cpu(), predicted_labels)\n        \n        del inputs, labels, outputs, preds, predicted_labels\n        torch.cuda.empty_cache()\n        \n        images_so_far += size\n        if images_so_far >= num_images:\n            break\n        \n    vgg.train(mode=was_training) # Revert model back to original training state","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a58f54f4940ccaab30210a4bb6c0191e42a089e3"},"cell_type":"code","source":"def eval_model(vgg, criterion):\n    since = time.time()\n    avg_loss = 0\n    avg_acc = 0\n    loss_test = 0\n    acc_test = 0\n    \n    test_batches = len(dataloaders[TEST])\n    print(\"Evaluating model\")\n    print('-' * 10)\n    \n    for i, data in enumerate(dataloaders[TEST]):\n        if i % 100 == 0:\n            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n\n        vgg.train(False)\n        vgg.eval()\n        inputs, labels = data\n\n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n        else:\n            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n\n        outputs = vgg(inputs)\n\n        _, preds = torch.max(outputs.data, 1)\n        loss = criterion(outputs, labels)\n\n        loss_test += loss.data[0]\n        acc_test += torch.sum(preds == labels.data)\n\n        del inputs, labels, outputs, preds\n        torch.cuda.empty_cache()\n        \n    avg_loss = loss_test / dataset_sizes[TEST]\n    avg_acc = acc_test / dataset_sizes[TEST]\n    \n    elapsed_time = time.time() - since\n    print()\n    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n    print('-' * 10)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d61f1a74f9ca1f488c54a5aeb3afa9873d77adca"},"cell_type":"code","source":"# Load the pretrained model from pytorch\nvgg16 = models.vgg16_bn()\nvgg16.load_state_dict(torch.load(\"../input/vgg16bn/vgg16_bn.pth\"))\nprint(vgg16.classifier[6].out_features) # 1000 \n\n\n# Freeze training for all layers\nfor param in vgg16.features.parameters():\n    param.require_grad = False\n\n# Newly created modules have require_grad=True by default\nnum_features = vgg16.classifier[6].in_features\nfeatures = list(vgg16.classifier.children())[:-1] # Remove last layer\nfeatures.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\nvgg16.classifier = nn.Sequential(*features) # Replace the model classifier\nprint(vgg16)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f7c78aac578d02f4b3178394f24ab605ce7e86d2"},"cell_type":"code","source":"# If you want to train the model for more than 2 epochs, set this to True after the first run\nresume_training = False\n\nif resume_training:\n    print(\"Loading pretrained model..\")\n    vgg16.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_v2-OCT_Retina.pt'))\n    print(\"Loaded!\")","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"645231b251ea5818aa855f60d7c7eb995e9a3382"},"cell_type":"code","source":"if use_gpu:\n    vgg16.cuda() #.cuda() will move everything to the GPU side\n    \ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"aeb6ba663706c01964dc41ae4a7a794f53ef427d"},"cell_type":"code","source":"print(\"Test before training\")\neval_model(vgg16, criterion)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"57407c0e53af664794bca729ab1f2de86a950638"},"cell_type":"code","source":"visualize_model(vgg16) #test before training","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5c8b187b948995f695ba6802bdafa48cb89fbc9a"},"cell_type":"code","source":"def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(vgg.state_dict())\n    best_acc = 0.0\n    \n    avg_loss = 0\n    avg_acc = 0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    \n    train_batches = len(dataloaders[TRAIN])\n    val_batches = len(dataloaders[VAL])\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0\n        loss_val = 0\n        acc_train = 0\n        acc_val = 0\n        \n        vgg.train(True)\n        \n        for i, data in enumerate(dataloaders[TRAIN]):\n            if i % 100 == 0:\n                print(\"\\rTraining batch {}/{}\".format(i, train_batches), end='', flush=True)\n                \n            # Use half training dataset\n            if i >= train_batches:\n                break\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n            else:\n                inputs, labels = Variable(inputs), Variable(labels)\n            \n            optimizer.zero_grad()\n            \n            outputs = vgg(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            loss_train += loss.data[0]\n            acc_train += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        print()\n        # * 2 as we only used half of the dataset\n        avg_loss = loss_train / dataset_sizes[TRAIN]\n        avg_acc = acc_train / dataset_sizes[TRAIN]\n        \n        vgg.train(False)\n        vgg.eval()\n            \n        for i, data in enumerate(dataloaders[VAL]):\n            if i % 100 == 0:\n                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n                \n            inputs, labels = data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n            else:\n                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n            \n            optimizer.zero_grad()\n            \n            outputs = vgg(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss_val += loss.data[0]\n            acc_val += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        avg_loss_val = loss_val / dataset_sizes[VAL]\n        avg_acc_val = acc_val / dataset_sizes[VAL]\n        \n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n        print('-' * 10)\n        print()\n        \n        if avg_acc_val > best_acc:\n            best_acc = avg_acc_val\n            best_model_wts = copy.deepcopy(vgg.state_dict())\n        \n    elapsed_time = time.time() - since\n    print()\n    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Best acc: {:.4f}\".format(best_acc))\n    \n    vgg.load_state_dict(best_model_wts)\n    return vgg","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"937fee22e8b4df5bf8648348a4fe5b3daed96b8f"},"cell_type":"code","source":"vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)\ntorch.save(vgg16.state_dict(), 'vgg16_trained_model.pt')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a014f48dce0a173db3d83dfa06563b94d11434c"},"cell_type":"code","source":"eval_model(vgg16, criterion)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"042a413b9dfeef0df5240b8090515706eb11806a"},"cell_type":"code","source":"visualize_model(vgg16, num_images=32)","execution_count":18,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}